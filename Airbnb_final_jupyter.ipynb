{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of pages: 17\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "import re \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.airbnb.com/s/Hawaii--United-States/homes?refinement_paths%5B%5D=%2Fhomes&place_id=ChIJBeB5Twbb_3sRKIbMdNKCd0s&query=Hawaii%2C%20United%20States&search_type=pagination&s_tag=iX5g1dsA&section_offset=8&items_offset=0\")\n",
    "\n",
    "\n",
    "#writing the csv file 'airbnb_1'\n",
    "csv_file = open('airbnb_2.csv', 'w', encoding='utf-8')\n",
    "writer = csv.writer(csv_file)\n",
    "\n",
    "\n",
    "writer.writerow(['title', 'neighborhood', 'rental_type', 'agg_star_rev', 'total_review_num', 'host_location'])\n",
    "\n",
    "\n",
    "number_pages = int(driver.find_elements_by_xpath('//ul[@data-id=\"SearchResultsPagination\"]/li/a')[-2].text)\n",
    "print(\"Total of pages: {}\".format(number_pages))\n",
    "print('=' * 50)\n",
    "\n",
    "#pages will scrape\n",
    "page_urls = ['https://airbnb.com/s/Hawaii--United-States/homes?refinement_paths%5B%5D=%2Fhomes&query=Hawaii%2C%20United%20States&place_id=ChIJBeB5Twbb_3sRKIbMdNKCd0s&search_type=pagination&s_tag=xG2i-o9D&_set_bev_on_new_domain=1563565303_iFR3lTys363oxr8W&section_offset=7&items_offset={}&adults=1'.format(18 * x) \n",
    "for x in range(0, number_pages + 1)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page number 1\n",
      "18 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 2\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 3\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 4\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 5\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 6\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 7\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 8\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 9\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 10\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 11\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 12\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 13\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 14\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 15\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 16\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 17\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n",
      "Scraping page number 18\n",
      "0 links is going to be scraped in this page\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "all_page_urls = []\n",
    "index = 1\n",
    "\n",
    "for url in page_urls:\n",
    "    # Check which page is been scraping\n",
    "    print(\"Scraping page number \" + str(index))\n",
    "\n",
    "    a = driver.find_elements_by_xpath('//div[@class=\"_8ssblpx\"]/div/div/div/div/div/div[2]/div/span/a')\n",
    "    detail_urls = [x.get_attribute(\"href\") for x in a]\n",
    "\n",
    "    driver.get(url)\n",
    "    print(str(len(detail_urls)) + \" links is going to be scraped in this page\")\n",
    "    print('=' * 50)\n",
    "    \n",
    "\n",
    "    all_page_urls.extend(detail_urls)\n",
    "    index += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of rentals: 18\n",
      "==================================================\n",
      "Scraping rental number 1 - 5.56% completed\n",
      "Scraping rental number 2 - 11.11% completed\n",
      "Scraping rental number 3 - 16.67% completed\n",
      "Scraping rental number 4 - 22.22% completed\n",
      "Scraping rental number 5 - 27.78% completed\n",
      "Scraping rental number 6 - 33.33% completed\n",
      "Scraping rental number 7 - 38.89% completed\n",
      "Scraping rental number 8 - 44.44% completed\n",
      "Scraping rental number 9 - 50.00% completed\n",
      "Scraping rental number 10 - 55.56% completed\n",
      "Scraping rental number 11 - 61.11% completed\n",
      "Scraping rental number 12 - 66.67% completed\n",
      "Scraping rental number 13 - 72.22% completed\n",
      "Scraping rental number 14 - 77.78% completed\n",
      "Scraping rental number 15 - 83.33% completed\n",
      "Scraping rental number 16 - 88.89% completed\n",
      "Scraping rental number 17 - 94.44% completed\n",
      "Scraping rental number 18 - 100.00% completed\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(\"Total of rentals: {}\".format(len(all_page_urls)))\n",
    "print('=' * 50)\n",
    "# Scraping each rental's page\n",
    "for url in all_page_urls:\n",
    "    print(\"Scraping rental number {} - {:0.2f}% completed\".format(index, (index / len(all_page_urls) * 100)))\n",
    "    driver.get(url)\n",
    "    result = {}\n",
    "    \n",
    "\n",
    "    ### rental data for properties\n",
    "\n",
    "    ## regular properties\n",
    "    try:\n",
    "        result['title'] = driver.find_element_by_xpath('//div[@itemprop=\"name\"]/span/h1').text\n",
    "    #luxe properties\n",
    "    except:\n",
    "        result['title'] = None\n",
    "\n",
    "        #result[\"title\"] = driver.find_element_by_xpath('//div[@style=\"margin-top: 12px; margin-bottom: 40px;\"]/div/section/h1/div').text\n",
    "    \n",
    "\n",
    "    try:\n",
    "        result['neighborhood'] = driver.find_element_by_xpath('//div[@class=\"_czm8crp\"]').text\n",
    "    except:\n",
    "        result['neighborhood'] = None\n",
    "        #result['neighborhood'] = driver.find_element_by_xpath('//div[@class=\"_ylytgbo\"]').text\n",
    "\n",
    "    try:\n",
    "        result['rental_type'] = driver.find_element_by_xpath('//div[@class=\"_1p3joamp\"]').text\n",
    "    except:\n",
    "        result['neighborhood'] = None\n",
    "        #result['rental_type'] = driver.find_element_by_xpath('//div[@class=\"_1vazeet6\"]').text\n",
    "\n",
    "    #result['featured_amenities'] =  driver.find_element_by_xpath('//table[@class=\"_zabnfs\"]/tbody/tr/td[2]/div').text\n",
    "    try:\n",
    "        result['agg_star_rev'] = driver.find_element_by_xpath('//div[@class=\"_l0ao8q\"]/div/div').get_attribute(\"content\")\n",
    "    except:\n",
    "        result['agg_star_rev'] = None\n",
    "        #result['agg_star_rev'] = driver.find_element_by_xpath('//div[@class=\"_36rlri\"]/span/span').get_attribute(\"aria-label\")\n",
    "\n",
    "    try:\n",
    "        result['total_review_num'] = driver.find_element_by_xpath('//span[@class=\"_s1tlw0m\"]').text\n",
    "    except:\n",
    "        result['total_review_num'] = None\n",
    "        #esult['total_review_num'] = driver.find_element_by_xpath('//span[@class=\"_1gvnvab\"]/span').text\n",
    "\n",
    "    try:\n",
    "        result['host_location'] =  driver.find_element_by_xpath('//div[@class=\"_czm8crp\"]/span').text\n",
    "    except:\n",
    "        result['host_location'] = None\n",
    "\n",
    "\n",
    "    #except:\n",
    "    #   result['rental_age'] = driver.find_element_by_xpath('//div[@class=\"_rh3vpp\"]/div/div[1]').text\n",
    "\n",
    "\n",
    "\n",
    "    index += 1\n",
    "    writer.writerow(result.values())\n",
    "\n",
    "csv_file.close()\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
